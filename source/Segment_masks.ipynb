{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z-zOTnyxxaer",
    "outputId": "d050cf7a-859a-4d37-f06b-812a5e6c30cd"
   },
   "outputs": [],
   "source": [
    "# Installing Segment Anything to local machine\n",
    "\n",
    "# pip install 'git+https://github.com/facebookresearch/segment-anything.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cq5DEaHSy0rW",
    "outputId": "5b1a8fe6-f154-4feb-9139-95c1a9cdcdee"
   },
   "outputs": [],
   "source": [
    "# Downloading model weights for segmentation\n",
    "\n",
    "# !wget https://dl.fbaipublicfiles.com/segment_anything/sam_vit_l_0b3195.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QcmBxv1SGIOe"
   },
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "import cv2\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9V3XL93izHxN",
    "outputId": "292c9ae1-5e07-4e7b-d703-2a756fb1a5a2"
   },
   "outputs": [],
   "source": [
    "# Building the Segmentation pipeline\n",
    "\n",
    "# config\n",
    "in_dir = '/content/input_images'\n",
    "out_dir = '/content/segment_masks'\n",
    "sam_model = \"vit_l\"\n",
    "sam_check = \"/content/sam_vit_l_0b3195.pth\"\n",
    "device = \"cuda\"\n",
    "transparency = 0.3\n",
    "max_masks = 300\n",
    "\n",
    "# list of random colors\n",
    "colors = []\n",
    "for i in range(max_masks):\n",
    "    colors.append(np.random.random((3)))\n",
    "\n",
    "def draw_segmentation(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    h, w = anns[0]['segmentation'].shape\n",
    "    image = np.zeros((h, w, 3), dtype=np.float64)\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    no_masks = min(len(sorted_anns), max_masks)\n",
    "    for i in range(no_masks):\n",
    "        # true/false segmentation\n",
    "        seg = sorted_anns[i]['segmentation']\n",
    "\n",
    "        # set segmentation to a random color\n",
    "        image[seg] = colors[i]\n",
    "    return image\n",
    "\n",
    "def process_image(img_path, out_path, mask_generator):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # mask generator wants the default uint8 image\n",
    "    masks = mask_generator.generate(image)\n",
    "\n",
    "    # convert to float64\n",
    "    image = image.astype(np.float64) / 255\n",
    "    seg = draw_segmentation(masks)\n",
    "\n",
    "    # add segmentation image on top of original image\n",
    "    image = seg\n",
    "\n",
    "    # convert back to uint8 for display/save\n",
    "    image = (255 * image).astype(np.uint8)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    # cv2.imshow(\"my img\", image)\n",
    "    # cv2.waitKey(-1)\n",
    "    cv2.imwrite(out_path, image)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # make sure output dir exists\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    # load SAM model + create mask generator\n",
    "    sam = sam_model_registry[sam_model](checkpoint=sam_check)\n",
    "    sam.to(device=device)\n",
    "    mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "    # process input directory\n",
    "    for img in tqdm(os.listdir(in_dir)):\n",
    "\n",
    "        # change extension of output image to .png\n",
    "        out_img = Path(img).stem + \".png\"\n",
    "        out_img = os.path.join(out_dir, out_img)\n",
    "\n",
    "        # if we can read/decode this file as an image\n",
    "        in_img = os.path.join(in_dir, img)\n",
    "        if cv2.haveImageReader(in_img):\n",
    "            process_image(in_img, out_img, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z4CMFUhk6Ieg"
   },
   "outputs": [],
   "source": [
    "# Function for generating annotation (segment) masks on sample image\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIvcbxL7z4ti"
   },
   "outputs": [],
   "source": [
    "# Initialising the SAM model\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MODEL_TYPE = \"vit_l\"\n",
    "\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=\"/content/sam_vit_l_0b3195.pth\")\n",
    "sam.to(device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3WuhJGeP2hYK"
   },
   "outputs": [],
   "source": [
    "# Segmenting sample images from the shipwreck dataset\n",
    "# This is applied to images before and after applying CLAHE\n",
    "\n",
    "mask_gen = SamAutomaticMaskGenerator(sam)\n",
    "\n",
    "image_bgr = cv2.imread('/content/test/c1754s413.jpg')\n",
    "image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n",
    "result = mask_gen.generate(image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "id": "nrTXdxND3q9L",
    "outputId": "26338ce4-d6e2-4128-a65d-59b7a33b695c"
   },
   "outputs": [],
   "source": [
    "# Displaying the original image and segmented image for comparison\n",
    "\n",
    "fig = plt.figure(figsize = (50,50))\n",
    "original = fig.add_subplot(2,2,1)\n",
    "original.imshow(image_bgr)\n",
    "plt.axis(\"off\")\n",
    "masked = fig.add_subplot(2,2,2)\n",
    "masked.imshow(image_bgr)\n",
    "show_anns(result)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
